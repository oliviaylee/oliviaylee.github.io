---
layout: archive
title: "Portfolio"
permalink: /portfolio/
author_profile: true
---

{% include base_path %}

Background
======
I graduated from Stanford with my M.S. with [Research Distinction](https://oliviaylee.github.io/files/Masters_Thesis.pdf){:target="_blank"} in Computer Science. Before that, I graduated with my B.S. with [Honors](https://purl.stanford.edu/jp127mt8218){:target="_blank"} in [Symbolic Systems](https://symsys.stanford.edu/){:target="_blank"} and minor in Mathematics. 

Inspired by my interdisciplinary coursework, I am drawn to research leveraging cognitive science for robot learning and visual understanding. I aim to better understand human cognitive processes, such as multimodal perception, curiosity, and interactive learning, to develop human-inspired learning algorithms for robotics.

In my downtime, I enjoy playing tennis, snowboarding, ashtanga yoga, science fiction, and brush calligraphy.

<!-- {% for post in site.portfolio %}
  {% include archive-single.html %}
{% endfor %} -->

Thesis Papers
======
<span style="color:#52ADC8">**Scaling Robot Learning without Scaling Human Effort**</span> [\[thesis\]](/files/Masters_Thesis.pdf){:target="_blank"} <br>
  <sub> *Master's Thesis* </sub> <br>
  <sub style="font-size:11px">*Topics: Robotics, Autonomous Reinforcement Learning, Vision-Language Models, Sim-to-Real Reinforcement Learning, Dexterous Manipulation, Learning from Human Demonstration*</sub>

<span style="color:#52ADC8">**Leveraging Affordance Representations for Robot Learning**</span> [\[thesis\]](/files/Honors_Thesis.pdf){:target="_blank"} [\[publication\]](https://doi.org/10.25740/jp127mt8218){:target="_blank"} <br>
  <sub> *Undergraduate Honors Thesis*</sub> <br>
  <sub style="font-size:11px">*Topics: Robotics, Online Reinforcement Learning, Vision-Language Models, Video Pre-training, Affordance Theory*</sub>

Teaching
======
<span style="color:#52ADC8">**Summer 2024: CS 229 Machine Learning**</span> <br>
   <sub> *Taught by Prof. Jehangir Amjad*</sub> <br>
   <sub style="font-size:11px">*Topics: Machine Learning, Supervised Learning, Unsupervised Learning*</sub>

<span style="color:#52ADC8">**Winter 2024, Spring 2024: CS 224N Natural Language Processsing with Deep Learning**</span> <br>
   <sub> *Taught by Prof. Tatsunori Hashimoto & Prof. Diyi Yang (Winter 2024) and Prof. Christopher Manning (Spring 2024)*</sub> <br>
    <sub style="font-size:11px">*Topics: Natural Language Processing, Machine Learning, Deep Learning*</sub>

<span style="color:#52ADC8">**Fall 2023, Fall 2024: CS 157 Computational Logic**</span> <br>
   <sub> *Taught by Prof. Michael Genesereth*</sub> <br>
   <sub style="font-size:11px">*Topics: Propositional Logic, Relational Logic, Functional Logic*</sub>

Computational Projects
======
<span style="color:#52ADC8">**Today Years Old: Adapting Language Models to Word Shifts**</span> [\[paper\]](/files/2023-win-cs224n-paper.pdf){:target="_blank"} [\[poster\]](/files/2023-win-cs224n-poster.pdf){:target="_blank"} [\[code\]](https://www.github.com/oliviaylee/today-years-old){:target="_blank"} <br>
  <sub> *Final report, poster, and code for CS 224N: Natural Language Processing with Deep Learning (Winter 2023)*<br>
  Finetuned GPT-2 and RoBERTa to predict word embeddings for novel lexical items from Urban Dictionary. </sub> <br>
  <sub style="font-size:11px">*Topics: Natural Language Processing, Machine Learning, Supervised Learning, Domain Adaptation*</sub>

<span style="color:#52ADC8">**A Shot in the Dark: Modeling Improved Zero-Shot and Few-Shot Transfer Learning with Self-Supervised Models for Sentiment Classification**</span> [\[paper\]](/files/2022-spr-cs229-paper.pdf){:target="_blank"} [\[poster\]](/files/2022-spr-cs229-poster.pdf){:target="_blank"} <br>
  <sub> *Final report and poster for CS 229: Machine Learning (Spring 2022)*<br>
  Transfer learning with self-supervised embeddings can improve model performance on sentiment classification tasks.</sub> <br>
  <sub style="font-size:11px">*Topics: Natural Language Processing, Machine Learning, Self-Supervised Learning, Transfer Learning*</sub>
   
<span style="color:#52ADC8">**Model Predictive Curiosity**</span> [\[paper\]](/files/2022-spr-psych240a-paper.pdf){:target="_blank"} [\[poster\]](/files/2022-spr-psych240a-poster.pdf){:target="_blank"} <br>
  <sub>*Final report and poster for PSYCH 240A: Curiosity in Artificial Intelligence (Spring 2022)*<br>
  Model Predictive Curiosity (MPCu) optimizes for high-curiosity action values and enriches multi-object interactions in a Box2D environment.</sub> <br>
  <sub style="font-size:11px">*Topics: Curiosity-Based Models, Model-Based Reinforcement Learning, Representation Learning, Self-Supervised Learning*</sub>

Philosophy Papers
======
<span style="color:#52ADC8">**The Missing Piece: Dispelling the Mystery of Introspective Illusion**</span> [\[paper\]](/files/2023-spr-phil186-paper.pdf){:target="_blank"} <br>
  <sub>*Final paper for PHIL 186: Philosophy of Mind (Spring 2023)*</sub> <br> <!-- I argue that explaining the potency of phenomenal illusions is the crucial missing piece for a sound illusionist theory. I present two main desiderata for a positive theory of illusionism by drawing connections to related theories of consciousness, namely global workspace theory (Dennett, 2001) and Buddhist philosophy. </sub> <br> -->
  <sub style="font-size:11px">*Topics: Consciousness, Illusionism, Higher-Order Thought Theory*</sub> 

<span style="color:#52ADC8">**Consciousness, Phenomenality, and the Representational Layer**</span> [\[paper\]](/files/2023-win-symsys202-paper.pdf){:target="_blank"} <br>
  <sub>*Final paper for SYMSYS 202: Theories of Consciousness (Winter 2023)*</sub> <br> <!-- I propose that metacognition on top of the representational layer, beyond mere possession of representational states, is critical for consciousness, and explore how phenomenality is introduced in this process. I discuss the implications of this proposal for the functional and evolutionary roles of consciousness.</sub> <br> -->
  <sub style="font-size:11px">*Topics: Consciousness, Representationalism, Phenomenality, Higher-Order Thought Theory, Global Workspace Theory*</sub>

<span style="color:#52ADC8">**Philosophy of Mind: Wittgenstein, The Unconscious Mind, and Self-Knowledge**</span> [\[paper\]](/files/2022-fall-oxfordphil-essays.pdf){:target="_blank"} <br>
  <sub>*Collection of essays for OSPOXFRD 199: Philosophy of Mind (Fall 2022)* </sub> <br> <!-- A compilation of essays written for a Directed Reading during my quarter abroad at Oxford. Topics include: other minds, the privacy of experience, the unconscious mind, and self-knowledge. -->
  <sub style="font-size:11px">*Topics: Philosophy of Mind, Philosophy of Psychology, Wittgenstein, Private Language Argument, Consciousness, Self-Knowledge*</sub>

<span style="color:#52ADC8">**Predictive Processing: Efficiently processing high-dimensional, multimodal inputs**</span> [\[paper\]](/files/2022-spr-symsys205-paper.pdf){:target="_blank"} <br>
  <sub>*Final paper for SYMSYS 205: The Philosophy and Science of Perception (Spring 2022)*</sub> <br> <!-- I explore the plausibility of the predictive processing framework over the standard bottom-up model of perception. I specifically explore efficient processing of high-dimensional multimodal inputs, where the qualitative space of each modality has unique dimensionality and structure.</sub> <br> -->
  <sub style="font-size:11px">*Topics: Multimodal Perception, Perceptual Cognition, Cognitive Processing*</sub>

<span style="color:#52ADC8">**The Future of Human-Machine Interaction: Keeping Humans in the Loop**</span> [\[paper\]](/files/2022-fall-ospoxfrd29-paper.pdf){:target="_blank"} <br>
  <sub>*Final paper for OSPOXFRD 29: Artificial Intelligence & Society (Fall 2022)*</sub> <br> <!-- The doomsday ending that humans will be demolished in the fierce intelligence competition with AI systems, while remarkably enduring, is a narrow view that distracts us from active measures that can be presently taken. A key tenet of AI development going forward should be keeping humans in the loop, and I evaluate three technical research areas facilitating human-in-the-loop AI development and deployment. Distinguishing between non-immediate decision making (e.g., data analytics, robotics) and time-sensitive, safety-critical decision making (e.g., autonomous vehicles, aircraft) is key to understanding how to best facilitate human-AI collaboration in each case.</sub> <br> -->
  <sub style="font-size:11px">*Topics: Human-AI Interaction, AI Safety, Human-In-The-Loop Development, Decision-Making*</sub>

Math Papers
======
<span style="color:#52ADC8">**Asymmetric Processes**</span> [\[paper\]](/files/2024-win-math101-paper2.pdf){:target="_blank"} <br>
  <sub>*Research report for MATH 101: Math Discovery Lab (Winter 2024)*<br>
  Studies the properties of probability distributions of particle configurations at equilibrium for asymmetric Markov models, specifically irreducibility, aperiodicity, and double stochasticity. </sub> <br>
  <sub style="font-size:11px">*Topics: Markov Processes, Markov Chains, Probability Theory*</sub> 

<span style="color:#52ADC8">**Infinite Coin Tosses**</span> [\[paper\]](/files/2024-win-math101-paper1.pdf){:target="_blank"} <br>
  <sub>*Research report for MATH 101: Math Discovery Lab (Winter 2024)*<br>
  Studies pathological behavior of cumulative distribution functions for infinite coin tosses in terms of continuity, differentiability, and arc length. </sub> <br>
  <sub style="font-size:11px">*Topics: Probability Theory, Continuous Random Variables*</sub>

<span style="color:#52ADC8">**Hilbert's 10th Problem**</span> [\[paper\]](/files/2023-spr-phil152-paper.pdf){:target="_blank"} <br>
  <sub>*Research report for PHIL 152: Computability and Logic (Spring 2023)*<br>
  A proof of Hilbert's 10th Problem: determining the solvability of Diophantine equations over integers.
  </sub> <br>
  <sub style="font-size:11px">*Topics: Computability Theory*</sub>