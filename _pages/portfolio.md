---
layout: archive
title: "Portfolio"
permalink: /portfolio/
author_profile: true
---

{% include base_path %}

Inspired by my interdisciplinary coursework, I am drawn to research leveraging cognitive science for robot learning and visual understanding. I aim to better understand human cognitive processes, such as multimodal perception, curiosity, and interactive learning, to develop human-inspired learning algorithms for robotics.

Below is a collection of works that embody my academic interests.

Background
======
I am a U.S. citizen, raised and educated in Singapore ðŸ‡¸ðŸ‡¬. Year by year, hereâ€™s what I explored, learned, and built: 
- At various points: Led product strategy at startups - deep tech (quantum computing) based in SG, AI-powered hiring based in Asia + US.
- 2021: Finding home at Stanford. Started robot learning research at IRIS Lab.
- Summer 2022: Developed low-code workflow automation tools at Salesforce in SF.
- Fall 2022: Studied abroad at Magdalen College, Oxford. Studied graph representation learning and philosophy of mind. Tried my hand at rowing!
- 2023: Led a project that became my honors thesis. Took more philosophy classes. Had fun enjoying a full Lake Lag and staffing a summer dorm.
- 2024: Graduated BS SymSys! Continued robot learning research at IPRL Lab.
- 2025: More research and thesis writing. Deep dive into startup strategy and scaling technical ventures with Accel Leadership Program.
- Now: Graduated MS CS! Preparing for the next chapter...

In my downtime, I enjoy playing tennis, snowboarding, ashtanga yoga, science fiction, and brush calligraphy.

<!-- {% for post in site.portfolio %}
  {% include archive-single.html %}
{% endfor %} -->

Thesis Papers
======
<span style="color:#52ADC8">**Scaling Robot Learning without Scaling Human Effort**</span> [\[thesis\]](/files/Masters_Thesis.pdf){:target="_blank"} <br>
  <sub> *Master's Thesis* </sub> <br>
  <sub style="font-size:11px">*Topics: Robotics, Autonomous Reinforcement Learning, Vision-Language Models, Sim-to-Real Reinforcement Learning, Dexterous Manipulation, Learning from Human Demonstration*</sub>

<span style="color:#52ADC8">**Leveraging Affordance Representations for Robot Learning**</span> [\[thesis\]](/files/Honors_Thesis.pdf){:target="_blank"} [\[publication\]](https://doi.org/10.25740/jp127mt8218){:target="_blank"} <br>
  <sub> *Undergraduate Honors Thesis*
  <!-- <br> Humans are capable of adapting to novel environments quickly using prior knowledge from past experiences. We can identify new instantiations of previously encountered object classes and easily apply previously learned skills to these new objects, both of which current embodied AI agents struggle with. Online reinforcement learning, where a robotic agent learns a mapping from states to actions to maximize a reward signal, provides a potential solution by enabling robots to learn from trial-and-error. However, current methods are sample-inefficient, lack shaping rewards, and require frequent resets. We propose a method to address the lack of shaping rewards using affordances, the action potential of objects, to create a dense shaping reward for online reinforcement learning. We leverage state-of-the-art vision-language models (VLMs) to predict keypoint-based affordance representations, which we use as intermediate dense rewards for online reinforcement learning, in addition to sparse task completion rewards. We demonstrate that dense shaping rewards speed up online reinforcement learning for robotic manipulation, and enables robots to succeed on a variety of object manipulation tasks, informed by human interaction priors encoded in VLMs.--> </sub> <br>
  <sub style="font-size:11px">*Topics: Robotics, Online Reinforcement Learning, Vision-Language Models, Video Pre-training, Affordance Theory*</sub>

Teaching
======
<span style="color:#52ADC8">**Summer 2024: CS 229 Machine Learning**</span> <br>
   <sub> *Taught by Prof. Jehangir Amjad*</sub> <br>
   <sub style="font-size:11px">*Topics: Machine Learning, Supervised Learning, Unsupervised Learning*</sub>

<span style="color:#52ADC8">**Winter 2024, Spring 2024: CS 224N Natural Language Processsing with Deep Learning**</span> <br>
   <sub> *Taught by Prof. Tatsunori Hashimoto / Prof. Diyi Yang (Winter 2024) and Prof. Christopher Manning (Spring 2024)*</sub> <br>
    <sub style="font-size:11px">*Topics: Natural Language Processing, Machine Learning, Deep Learning*</sub>

<span style="color:#52ADC8">**Fall 2023, Fall 2024: CS 157 Computational Logic**</span> <br>
   <sub> *Taught by Prof. Michael Genesereth*</sub> <br>
   <sub style="font-size:11px">*Topics: Propositional Logic, Relational Logic, Functional Logic*</sub>

Computational Projects
======
<span style="color:#52ADC8">**Today Years Old: Adapting Language Models to Word Shifts**</span> [\[paper\]](/files/2023-win-cs224n-paper.pdf){:target="_blank"} [\[poster\]](/files/2023-win-cs224n-poster.pdf){:target="_blank"} [\[code\]](https://www.github.com/oliviaylee/today-years-old){:target="_blank"} <br>
  <sub> *Final report, poster, and code for Stanford's CS 224N: Natural Language Processing with Deep Learning (Winter 2023)*<br>
  Finetuned GPT-2 and RoBERTa to predict word embeddings for novel lexical items from Urban Dictionary given their definitions. </sub> <br>
  <sub style="font-size:11px">*Topics: Natural Language Processing, Machine Learning, Supervised Learning, Domain Adaptation*</sub>

<span style="color:#52ADC8">**A Shot in the Dark: Modeling Improved Zero-Shot and Few-Shot Transfer Learning with Self-Supervised Models for Sentiment Classification**</span> [\[paper\]](/files/2022-spr-cs229-paper.pdf){:target="_blank"} [\[poster\]](/files/2022-spr-cs229-poster.pdf){:target="_blank"} <br>
  <sub> *Final report and poster for Stanford's CS 229: Machine Learning (Spring 2022)*<br>
  Modeled transfer learning with self-supervised embeddings to optimize model performance on sentiment classification tasks.</sub> <br>
  <sub style="font-size:11px">*Topics: Natural Language Processing, Machine Learning, Self-Supervised Learning, Transfer Learning*</sub>
   
<span style="color:#52ADC8">**Model Predictive Curiosity**</span> [\[paper\]](/files/2022-spr-psych240a-paper.pdf){:target="_blank"} [\[poster\]](/files/2022-spr-psych240a-poster.pdf){:target="_blank"} <br>
  <sub>*Final report and poster for Stanford's PSYCH 240A: Curiosity in Artificial Intelligence (Spring 2022)*<br>
  Proposed Model Predictive Curiosity (MPCu) to optimize for high-curiosity action values and enrich multi-object interactions in a Box2D environment.</sub> <br>
  <sub style="font-size:11px">*Topics: Curiosity-Based Models, Model-Based Reinforcement Learning, Representation Learning, Self-Supervised Learning*</sub>

<!-- <span style="color:#52ADC8">**Machine Learning-based platform using iBeacon Sensors for Product Location and Indoor Navigation to Improve Consumer Retail Experience**</span><br>
  <sub>*High school research engineering project (2018-2019)*<br>
  Trained an automatic speech recognition engine contextualized to Singaporean accents and terminology. Created a mobile app to help consumers navigate local supermarkets with verbal queries.</sub> <br>
  <sub style="font-size:11px">*Topics: Natural Language Processing, Speech Recognition, Speech-To-Text, Recommendation Systems, Shortest Path Generation, Indoor Geolocation, Bluetooth Sensor Systems*</sub> -->

Philosophy Papers
======
<span style="color:#52ADC8">**The Missing Piece: Dispelling the Mystery of Introspective Illusion**</span> [\[paper\]](/files/2023-spr-phil186-paper.pdf){:target="_blank"} <br>
  <sub>*Final paper for Stanford's PHIL 186: Philosophy of Mind (Spring 2023)*<br>
  I argue that explaining the potency of phenomenal illusions is the crucial missing piece for a sound illusionist theory. I present two main desiderata for a positive theory of illusionism by drawing connections to related theories of consciousness, namely global workspace theory (Dennett, 2001) and Buddhist philosophy. </sub> <br>
  <sub style="font-size:11px">*Topics: Consciousness, Illusionism, Higher-Order Thought Theory, Wittgenstein*</sub> 

<span style="color:#52ADC8">**Consciousness, Phenomenality, and the Representational Layer**</span> [\[paper\]](/files/2023-win-symsys202-paper.pdf){:target="_blank"} <br>
  <sub>*Final paper for Stanford's SYMSYS 202: Theories of Consciousness (Winter 2023)*<br>
  I propose that metacognition on top of the representational layer, beyond mere possession of representational states, is critical for consciousness, and explore how phenomenality is introduced in this process. I discuss the implications of this proposal for the functional and evolutionary roles of consciousness.</sub> <br>
  <sub style="font-size:11px">*Topics: Consciousness, Representationalism, Phenomenality, Higher-Order Thought Theory, Global Workspace Theory*</sub>

<span style="color:#52ADC8">**Philosophy of Mind: Wittgenstein, The Unconscious Mind, and Self-Knowledge**</span> [\[paper\]](/files/2022-fall-oxfordphil-essays.pdf){:target="_blank"} <br>
  <sub>*Collection of essays for OSPOXFRD 199: Philosophy of Mind (Fall 2022)*<br>
  A compilation of essays written for my Directed Reading in Philosophy of Mind, during my quarter abroad at Oxford. Each essay was written to prepare for biweekly tutorial discussions over the quarter. Topics included other minds, the privacy of experience, the unconscious mind, and self-knowledge.
  </sub> <br>
  <sub style="font-size:11px">*Topics: Philosophy of Mind, Philosophy of Psychology, Wittgenstein, Private Language Argument, Consciousness, Self-Knowledge*</sub>

<span style="color:#52ADC8">**Predictive Processing: Efficiently processing high-dimensional, multimodal inputs**</span> [\[paper\]](/files/2022-spr-symsys205-paper.pdf){:target="_blank"} <br>
  <sub>*Final paper for Stanford's SYMSYS 205: The Philosophy and Science of Perception (Spring 2022)*<br>
  I explore the plausibility of the predictive processing framework over the standard bottom-up model of perception. I specifically explore efficient processing of high-dimensional multimodal inputs, where the qualitative space of each modality has unique dimensionality and structure.</sub> <br>
  <sub style="font-size:11px">*Topics: Multimodal Perception, Perceptual Cognition, Cognitive Processing*</sub>

<span style="color:#52ADC8">**Large Language Models: Intelligence, Understanding, and Intentionality**</span> [\[paper\]](/files/2021-fall-symsys207-paper.pdf){:target="_blank"} <br>
  <sub>*Final paper for Stanford's SYMSYS 207: Conceptual Issues in Cognitive Neuroscience (Fall 2021)*<br>
  I argue that modern large language models (LLMs) cannot achieve strong intelligence.
  </sub> <br>
  <sub style="font-size:11px">Author's Note (March 2023): In hindsight, I acknowledge this paper does not give sufficient credit to the impressive emergent behaviors observed in LLMs. However, my stance towards purely language-based models are still generally aligned with this paper. Another work that articulates views I am sympathetic to is [Shanahan (2022)](https://arxiv.org/pdf/2212.03551.pdf){:target="_blank"}. That said, there are many cool developments expanding on LLMs (like vision-language models, or grounded language models more generally) that I'm excited about! </sub> <br>
  <sub style="font-size:11px">*Topics: Natural Language Processing, Artificial Intelligence, Natural Language Understanding, Intentionality*</sub>

Mathematics Papers
======
<span style="color:#52ADC8">**Asymmetric Processes**</span> [\[paper\]](/files/2024-win-math101-paper2.pdf){:target="_blank"} <br>
  <sub>*Research paper for Stanford's MATH 101: Math Discovery Lab (Winter 2024)*<br>
  Analyzes two asymmetric Markov models: first where particle number stays constant, and second where particles enter and exit at certain rates. We study probability distributions of particle configurations at equilibrium, and properties such as average particle speed, irreducibility, aperiodicity, and double stochasticity. </sub> <br>
  <sub style="font-size:11px">*Topics: Markov Processes, Markov Chains, Probability Theory*</sub> 

<span style="color:#52ADC8">**Infinite Coin Tosses**</span> [\[paper\]](/files/2024-win-math101-paper1.pdf){:target="_blank"} <br>
  <sub>*Research paper for Stanford's MATH 101: Math Discovery Lab (Winter 2024)*<br>
  Explores cumulative distribution functions for infinite coin tosses, parameterized by the probability *p* of flipping heads. We graph the outcomes of simulated coin flips and study properties of the cumulative distribution function, analyzing its pathological behavior in terms of continuity, differentiability, and arc length. </sub> <br>
  <sub style="font-size:11px">*Topics: Probability Theory, Continuous Random Variables*</sub>

<span style="color:#52ADC8">**Hilbert's 10th Problem**</span> [\[paper\]](/files/2023-spr-phil152-paper.pdf){:target="_blank"} <br>
  <sub>*Research paper for Stanford's PHIL 152: Computability and Logic (Spring 2023)*<br>
  A proof of Hilbert's 10th Problem: determining the solvability of Diophantine equations over integers.
  </sub> <br>
  <sub style="font-size:11px">*Topics: Computability Theory*</sub>

Technical Reports
======
<span style="color:#52ADC8">**The Future of Human-Machine Interaction: Keeping Humans in the Loop**</span> [\[paper\]](/files/2022-fall-ospoxfrd29-paper.pdf){:target="_blank"} <br>
  <sub>*Final paper for Stanford's OSPOXFRD 29: Artificial Intelligence & Society (Fall 2022)* <br>
  The doomsday ending that humans will be demolished in the fierce intelligence competition with AI systems, while remarkably enduring, is a narrow view that distracts us from active measures that can be presently taken. A key tenet of AI development going forward should be keeping humans in the loop, and I evaluate three technical research areas facilitating human-in-the-loop AI development and deployment. Distinguishing between non-immediate decision making (e.g., data analytics, robotics) and time-sensitive, safety-critical decision making (e.g., autonomous vehicles, aircraft) is key to understanding how to best facilitate human-AI collaboration in each case.</sub> <br>
  <sub style="font-size:11px">*Topics: Human-AI Interaction, AI Safety, Human-In-The-Loop Development, Decision-Making*</sub>

<span style="color:#52ADC8">**A Proposal for Building Safety Benchmarking Services in CAIS systems**</span> [\[paper\]](/files/2021-spr-seri-paper.pdf){:target="_blank"} <br>
  <sub>*Final report for Stanford Existential Risk Initiative's AI research program (Spring 2021)*<br>
  I propose a protocol encompassing safety benchmarking services for CAIS systems, ranging from pre-deployment safety benchmarks applied during model training to post-deployment safety benchmarks.</sub> <br>
  <sub style="font-size:11px">*Topics: AI Safety, Benchmarking Tools, AI Existential Risk*</sub>

<span style="color:#52ADC8">**Implications of the Comprehensive AI Services Framework on AI Safety Research**</span> [\[paper\]](/files/2021-win-seri-paper.pdf){:target="_blank"} <br>
  <sub>*Final report for Stanford Existential Risk Initiative's AI research program (Winter 2021)*<br>
  I argue that developing powerful AI systems in line with the Comprehensive AI Systems (CAIS) framework outlined in [*Reframing Superintelligence* (2019)](https://www.fhi.ox.ac.uk/wp-content/uploads/Reframing_Superintelligence_FHI-TR-2019-1.1-1.pdf){:target="_blank"} should be encouraged, due to the potential for enhanced safety measures to mitigate AI existential risk.</sub> <br>
  <sub style="font-size:11px">*Topics: AI Safety, Hierarchical Reinforcement Learning, AI Existential Risk*</sub>

<span style="color:#52ADC8">**Autonomous Vehicles: From Vision to Reality**</span> [\[paper\]](/files/2020-fall-cs56n-paper.pdf){:target="_blank"} <br>
  <sub>*Final paper for Stanford's CS 56N: Great Discoveries and Inventions in Computing, taught by Prof. John Hennessey (Fall 2020)*<br>
  We analyze current developments in autonomous driving, and discuss technological hurdles in secure, scalable implementation of autonomous systems.</sub> <br>
  <sub style="font-size:11px">*Topics: Autononous Driving, Computer Vision, LiDAR/RADAR Sensor Systems, AI Safety*</sub>

<!-- <span style="color:#52ADC8">**When Worlds Collide: Challenges and Opportunities in Virtual Reality**</span> [\[paper\]](/files/2021-fall-history44q-paper.pdf){:target="_blank"} [\[publication\]](https://ojs.stanford.edu/ojs/index.php/sjfgss/article/view/2109){:target="_blank"} <br>
  <sub>*Final paper for Stanford's HISTORY 44Q: Gendered Innovations in Science, Medicine, Engineering, and Environment (Fall 2021)<br>
  Published in peer-reviewed journal, Embodied: The Stanford Undergraduate Journal of Feminist, Gender, and Sexuality Studies*<br>
  I explore virtual reality (VR) software applications that contain discriminatory content and promote harassment behaviors, and explore innovation processes and design choices to reframe VR applications so that they promote gender and social equality. </sub> <br>
  <sub style="font-size:11px">*Topics: Virtual Reality, Gendered Innovations*</sub>
  <!-- I explore virtual reality (VR) software applications that contain discriminatory content and promote harassment behaviors towards historically underrepresented communities, and identify innovation processes to reframe VR applications so that they promote gender and social equality. I also explore design choices in VR hardware that tend to exclude females. To address this, I propose a better sex balance in research participants is needed to rethink reference models for VR hardware, leading to more sex-sensitive VR headsets. -->
