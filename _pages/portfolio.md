---
layout: archive
title: "Portfolio"
permalink: /portfolio/
author_profile: true
---

{% include base_path %}

An assortment of works that summarize my academic interests. 

<!-- {% for post in site.portfolio %}
  {% include archive-single.html %}
{% endfor %} -->

Computational Projects
======
<span style="color:#52ADC8">**A Shot in the Dark: Modeling Improved Zero-Shot and Few-Shot Transfer Learning with Self-Supervised Models for Sentiment Classification**</span> [\[paper\]](/files/2022-spr-cs229-paper.pdf){:target="_blank"} [\[poster\]](/files/2022-spr-cs229-poster.pdf){:target="_blank"} <br>
   <sub> *Final report and poster for Stanford's CS229: Machine Learning (Spring 2022)*<br>
    Our team modeled transfer learning with self-supervised embeddings and supervised models at various scales to optimize model performance on sentiment classification tasks compared to DistilBERT.</sub> 
    <sub style="font-size:9px">*Topics: Natural Language Processing, Machine Learning, Self-Supervised Learning, Transfer Learning*</sub>
   
<span style="color:#52ADC8">**Model Predictive Curiosity**</span> [\[paper\]](/files/2022-spr-psych240a-paper.pdf){:target="_blank"} [\[poster\]](/files/2022-spr-psych240a-poster.pdf){:target="_blank"} <br>
  <sub>*Final report and poster for Stanford's PSYCH 240A: Curiosity in Artificial Intelligence (Spring 2022)*<br>
  Our team proposed Model Predictive Curiosity (MPCu), a framework that backpropagates on curiosity values predicted by a forward dynamics model to select curiosity-maximizing actions.
  We demonstrated the capability of MPCu to optimize for high-curiosity action values and enrich multi-object interactions in Box2D environment.</sub>
  <sub style="font-size:9px">*Topics: Curiosity-Based Models, Model-Based Reinforcement Learning, Representation Learning, Self-Supervised Learning*</sub>

<span style="color:#52ADC8">**Machine Learning-based platform using iBeacon Sensors for Product Location and Indoor Navigation to Improve Consumer Retail Experience**</span><br>
  <sub>*High school research engineering project (2018-2019)*<br>
  Our team trained an automatic speech recognition engine contextualized to Singaporean accents and terminology, which we incorporated into a mobile app 
  to help consumers navigate local supermarkets with verbal queries. During testing, we combined the mobile app with bluetooth low-energy sensors in a 
  lattice formation in the store to identify the user's position relative to the intended item, then generating and displaying the shortest path.</sub>
  <sub style="font-size:9px">*Topics: Natural Language Processing, Recommendation Systems, Machine Learning, Indoor Geolocation, Bluetooth Sensor Systems*</sub>

Philosophy Papers
======
<span style="color:#52ADC8">**Predictive Processing: Efficiently processing high-dimensional, multimodal inputs**</span> [\[paper\]](/files/2022-spr-symsys205-paper.pdf){:target="_blank"} <br>
  <sub>*Final paper for Stanford's SYMSYS 205: The Philosophy and Science of Perception (Spring 2022)*<br>
  I argue for the plausibility of the predictive processing framework over the standard bottom-up 
  model of perception, especially in the context of efficiently processing high-dimensional 
  multimodal inputs, where the qualitative space of each modality has unique dimensionality and structure.</sub>
  <sub style="font-size:9px">*Topics: Multimodal Perception, Perceptual Cognition, Cognitive Processing*</sub>

<span style="color:#52ADC8">**Large Language Models: Intelligence, Understanding, and Intentionality**</span> [\[paper\]](/files/2021-fall-symsys207-paper.pdf){:target="_blank"} <br>
  <sub>*Final paper for Stanford's SYMSYS 207: Conceptual Issues in Cognitive Neuroscience (Fall 2021)*<br>
  I argue that modern large language models (LLMs) cannot achieve strong intelligence. LLMs do not learn quickly and flexibly, 
  nor do they employ heuristics for inference-making in a manner that an intelligent system would. Furthermore, LLMs have 
  limited capacity for understanding beyond symbol manipulation, and are purely reactional systems that lack intentionality.</sub>
  <sub style="font-size:9px">*Topics: Natural Language Processing, Artificial Intelligence, Natural Language Understanding, Intentionality*</sub>

Technical Reports
======
<span style="color:#52ADC8">**Implications of the Comprehensive AI Services Framework on AI Safety Research**</span> [\[paper\]](/files/2021-win-seri-paper.pdf){:target="_blank"} <br>
  <sub>*Final report for Stanford Existential Risk Initiative's AI research program (Winter 2021)*<br>
  I argue that developing powerful AI systems in line with the Comprehensive AI Systems (CAIS) framework outlined in
  Eric K. Drexler's [*Reframing Superintelligence* (2019)](https://www.fhi.ox.ac.uk/wp-content/uploads/Reframing_Superintelligence_FHI-TR-2019-1.1-1.pdf){:target="_blank"} is not just likely but should be encouraged, due to the potential 
  for enhanced safety measures to mitigate AI existential risk.</sub>
  <sub style="font-size:9px">*Topics: AI Safety, Hierarchical Reinforcement Learning, AI Existential Risk*</sub>

<span style="color:#52ADC8">**A Proposal for Building Safety Benchmarking Services in CAIS systems**</span> [\[paper\]](/files/2021-spr-seri-paper.pdf){:target="_blank"} <br>
  <sub>*Final report for Stanford Existential Risk Initiative's AI research program (Spring 2021)*<br>
  I propose a protocol encompassing safety benchmarking services for CAIS systems, ranging from pre-deployment safety
  benchmarks that are applied during model training (transparency tools, systems enabling robust and safe exploration, 
  and performance when subject to adversarial policies) to post-deployment safety benchmarks that are applied during
  model application (monitoring systems and trip wires to ensure agent behavior is within safety standards and expectations).</sub>
  <sub style="font-size:9px">*Topics: AI Safety, Benchmarking Tools, AI Existential Risk*</sub>

Commentaries
======
<span style="color:#52ADC8">**When Worlds Collide: Challenges and Opportunities in Virtual Reality**</span> [\[paper\]](/files/2021-fall-history44q-paper.pdf){:target="_blank"} [\[publication\]](https://ojs.stanford.edu/ojs/index.php/sjfgss/article/view/2109){:target="_blank"} <br>
  <sub>*Final paper for Stanford's HISTORY 44Q: Gendered Innovations in Science, Medicine, Engineering, and Environment (Fall 2021). Published in peer-reviewed journal, Embodied: The Stanford Undergraduate Journal of Feminist, Gender, and Sexuality Studies*<br>
  I explore virtual reality (VR) software applications that contain discriminatory content and promote harassment behaviors towards historically underrepresented communities, and
  identify innovation processes to reframe VR applications so that they promote gender and social equality. I also explore design choices in VR hardware that tend to exclude females. 
  To address this, I propose a better sex balance in research participants is needed to rethink reference models for VR hardware, leading to more sex-sensitive VR headsets.</sub>
  <sub style="font-size:9px">*Topics: Virtual Reality, Gendered Innovations*</sub>
